{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45b39c71-bacc-4b90-9705-243944205556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dim_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6b823e4-d573-4b90-a429-75f7965e16fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from functools import reduce\n",
    "from operator import add\n",
    " \n",
    "# =====================================================\n",
    "# DIMENSION TABLES - ALL STREAMING WITH NATURAL KEYS\n",
    "# =====================================================\n",
    " \n",
    "@dlt.table(\n",
    "    name=\"gold.dim_date\",\n",
    "    comment=\"Date dimension table with calendar attributes - Streaming with Natural Keys\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"delta.enableChangeDataFeed\": \"true\"\n",
    "    }\n",
    ")\n",
    "def dim_date():\n",
    "    \"\"\"Create date dimension as a streaming table using date as natural key\"\"\"\n",
    "   \n",
    "    # Read from silver streaming tables\n",
    "    chicago_dates = dlt.read_stream(\"silver.chicago_inspections_silver\").select(\"inspection_date\")\n",
    "    dallas_dates = dlt.read_stream(\"silver.dallas_inspections_silver\").select(\"inspection_date\")\n",
    "   \n",
    "    # Union all dates\n",
    "    all_dates = chicago_dates.union(dallas_dates).select(\n",
    "        to_date(col(\"inspection_date\")).alias(\"date_col\")\n",
    "    ).dropDuplicates([\"date_col\"])\n",
    "   \n",
    "    # Create date dimension with natural key\n",
    "    date_dim = all_dates.select(\n",
    "        date_format(col(\"date_col\"), \"yyyyMMdd\").cast(\"int\").alias(\"date_id_nk_pk\"),  # Natural key\n",
    "        col(\"date_col\").alias(\"date_num\"),\n",
    "        date_format(col(\"date_col\"), \"EEEE\").alias(\"day_name\"),\n",
    "        dayofmonth(col(\"date_col\")).alias(\"day_num\"),\n",
    "        date_format(col(\"date_col\"), \"E\").alias(\"day_abbr\"),\n",
    "        when(dayofweek(col(\"date_col\")).isin(1, 7), True).otherwise(False).alias(\"is_weekend\"),\n",
    "        date_format(col(\"date_col\"), \"MMMM\").alias(\"month_name\"),\n",
    "        date_format(col(\"date_col\"), \"MMM\").alias(\"month_abbr\"),\n",
    "        month(col(\"date_col\")).alias(\"month_num\"),\n",
    "        dayofweek(col(\"date_col\")).alias(\"dt\"),\n",
    "        year(col(\"date_col\")).alias(\"year_num\"),\n",
    "        date_format(col(\"date_col\"), \"yyyyMMdd\").cast(\"varchar(50)\").alias(\"data_source_id\"),\n",
    "        date_format(col(\"date_col\"), \"yyyy-MM-dd\").alias(\"data_workflow_name\"),\n",
    "        date_format(col(\"date_col\"), \"yyyyMMdd\").cast(\"varchar(50)\").alias(\"dw_job_id\"),\n",
    "        current_timestamp().alias(\"dw_load_dt\")\n",
    "    )\n",
    "   \n",
    "    return date_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f60d8448-ee10-4764-a8fc-0b9bd5e1284e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dim_Location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b539762-209b-4795-9ec5-221374b3a150",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"gold.dim_location\",\n",
    "    comment=\"Location dimension with address and geographic details - Streaming with Natural Keys\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"delta.enableChangeDataFeed\": \"true\"\n",
    "    }\n",
    ")\n",
    "def dim_location():\n",
    "    \"\"\"Create location dimension as a streaming table using location_id as natural key\"\"\"\n",
    "   \n",
    "    # Chicago locations\n",
    "    chicago_locations = dlt.read_stream(\"silver.chicago_inspections_silver\").select(\n",
    "        concat_ws(\"_\", lit(\"CHI\"), col(\"address\"), col(\"zip\")).alias(\"location_id_nk_pk\"),  # Natural key\n",
    "        col(\"address\").alias(\"street_address\"),\n",
    "        col(\"city\"),\n",
    "        col(\"state\"),\n",
    "        col(\"zip\"),\n",
    "        col(\"latitude\").cast(\"double\"),\n",
    "        col(\"longitude\").cast(\"double\"),\n",
    "        lit(\"CHI\").alias(\"source_city\")\n",
    "    ).dropDuplicates([\"location_id_nk_pk\"])\n",
    "   \n",
    "    # Dallas locations\n",
    "    dallas_locations = dlt.read_stream(\"silver.dallas_inspections_silver\").select(\n",
    "        concat_ws(\"_\", lit(\"DAL\"), col(\"street_address\"), col(\"zip_code\")).alias(\"location_id_nk_pk\"),  # Natural key\n",
    "        col(\"street_address\"),\n",
    "        lit(\"Dallas\").alias(\"city\"),\n",
    "        lit(\"TX\").alias(\"state\"),\n",
    "        col(\"zip_code\").alias(\"zip\"),\n",
    "        col(\"lat\").cast(\"double\").alias(\"latitude\"),\n",
    "        col(\"long\").cast(\"double\").alias(\"longitude\"),\n",
    "        lit(\"DAL\").alias(\"source_city\")\n",
    "    ).dropDuplicates([\"location_id_nk_pk\"])\n",
    "   \n",
    "    # Union locations\n",
    "    all_locations = chicago_locations.unionByName(dallas_locations)\n",
    "   \n",
    "    # Format columns without surrogate keys\n",
    "    dim_location = all_locations.select(\n",
    "        col(\"location_id_nk_pk\").cast(\"varchar(200)\"),  # Natural key as primary key\n",
    "        col(\"street_address\").cast(\"varchar(150)\"),\n",
    "        col(\"city\").cast(\"varchar(50)\"),\n",
    "        col(\"state\").cast(\"varchar(50)\"),\n",
    "        col(\"zip\").cast(\"varchar(50)\"),\n",
    "        col(\"latitude\").cast(\"float\"),\n",
    "        col(\"longitude\").cast(\"float\"),\n",
    "        col(\"location_id_nk_pk\").cast(\"varchar(200)\").alias(\"location\"),\n",
    "        col(\"location_id_nk_pk\").cast(\"varchar(200)\").alias(\"data_source_id\"),\n",
    "        col(\"source_city\").cast(\"varchar(50)\").alias(\"data_workflow_name\"),\n",
    "        col(\"location_id_nk_pk\").cast(\"varchar(200)\").alias(\"dw_job_id\"),\n",
    "        current_timestamp().alias(\"dw_load_dt\")\n",
    "    )\n",
    "   \n",
    "    return dim_location"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DIm_and_Fact_Tables_With_SCD_Type_2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
