{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45b39c71-bacc-4b90-9705-243944205556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dim_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6b823e4-d573-4b90-a429-75f7965e16fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from functools import reduce\n",
    "from operator import add\n",
    " \n",
    "# =====================================================\n",
    "# DIMENSION TABLES - ALL STREAMING WITH NATURAL KEYS\n",
    "# =====================================================\n",
    " \n",
    "@dlt.table(\n",
    "    name=\"gold.dim_date\",\n",
    "    comment=\"Date dimension table with calendar attributes - Streaming with Natural Keys\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"delta.enableChangeDataFeed\": \"true\"\n",
    "    }\n",
    ")\n",
    "def dim_date():\n",
    "    \"\"\"Create date dimension as a streaming table using date as natural key\"\"\"\n",
    "   \n",
    "    # Read from silver streaming tables\n",
    "    chicago_dates = dlt.read_stream(\"silver.chicago_inspections_silver\").select(\"inspection_date\")\n",
    "    dallas_dates = dlt.read_stream(\"silver.dallas_inspections_silver\").select(\"inspection_date\")\n",
    "   \n",
    "    # Union all dates\n",
    "    all_dates = chicago_dates.union(dallas_dates).select(\n",
    "        to_date(col(\"inspection_date\")).alias(\"date_col\")\n",
    "    ).dropDuplicates([\"date_col\"])\n",
    "   \n",
    "    # Create date dimension with natural key\n",
    "    date_dim = all_dates.select(\n",
    "        date_format(col(\"date_col\"), \"yyyyMMdd\").cast(\"int\").alias(\"date_id_nk_pk\"),  # Natural key\n",
    "        col(\"date_col\").alias(\"date_num\"),\n",
    "        date_format(col(\"date_col\"), \"EEEE\").alias(\"day_name\"),\n",
    "        dayofmonth(col(\"date_col\")).alias(\"day_num\"),\n",
    "        date_format(col(\"date_col\"), \"E\").alias(\"day_abbr\"),\n",
    "        when(dayofweek(col(\"date_col\")).isin(1, 7), True).otherwise(False).alias(\"is_weekend\"),\n",
    "        date_format(col(\"date_col\"), \"MMMM\").alias(\"month_name\"),\n",
    "        date_format(col(\"date_col\"), \"MMM\").alias(\"month_abbr\"),\n",
    "        month(col(\"date_col\")).alias(\"month_num\"),\n",
    "        dayofweek(col(\"date_col\")).alias(\"dt\"),\n",
    "        year(col(\"date_col\")).alias(\"year_num\"),\n",
    "        date_format(col(\"date_col\"), \"yyyyMMdd\").cast(\"varchar(50)\").alias(\"data_source_id\"),\n",
    "        date_format(col(\"date_col\"), \"yyyy-MM-dd\").alias(\"data_workflow_name\"),\n",
    "        date_format(col(\"date_col\"), \"yyyyMMdd\").cast(\"varchar(50)\").alias(\"dw_job_id\"),\n",
    "        current_timestamp().alias(\"dw_load_dt\")\n",
    "    )\n",
    "   \n",
    "    return date_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f60d8448-ee10-4764-a8fc-0b9bd5e1284e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dim_Location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b539762-209b-4795-9ec5-221374b3a150",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"gold.dim_location\",\n",
    "    comment=\"Location dimension with address and geographic details - Streaming with Natural Keys\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"delta.enableChangeDataFeed\": \"true\"\n",
    "    }\n",
    ")\n",
    "def dim_location():\n",
    "    \"\"\"Create location dimension as a streaming table using location_id as natural key\"\"\"\n",
    "   \n",
    "    # Chicago locations\n",
    "    chicago_locations = dlt.read_stream(\"silver.chicago_inspections_silver\").select(\n",
    "        concat_ws(\"_\", lit(\"CHI\"), col(\"address\"), col(\"zip\")).alias(\"location_id_nk_pk\"),  # Natural key\n",
    "        col(\"address\").alias(\"street_address\"),\n",
    "        col(\"city\"),\n",
    "        col(\"state\"),\n",
    "        col(\"zip\"),\n",
    "        col(\"latitude\").cast(\"double\"),\n",
    "        col(\"longitude\").cast(\"double\"),\n",
    "        lit(\"CHI\").alias(\"source_city\")\n",
    "    ).dropDuplicates([\"location_id_nk_pk\"])\n",
    "   \n",
    "    # Dallas locations\n",
    "    dallas_locations = dlt.read_stream(\"silver.dallas_inspections_silver\").select(\n",
    "        concat_ws(\"_\", lit(\"DAL\"), col(\"street_address\"), col(\"zip_code\")).alias(\"location_id_nk_pk\"),  # Natural key\n",
    "        col(\"street_address\"),\n",
    "        lit(\"Dallas\").alias(\"city\"),\n",
    "        lit(\"TX\").alias(\"state\"),\n",
    "        col(\"zip_code\").alias(\"zip\"),\n",
    "        col(\"lat\").cast(\"double\").alias(\"latitude\"),\n",
    "        col(\"long\").cast(\"double\").alias(\"longitude\"),\n",
    "        lit(\"DAL\").alias(\"source_city\")\n",
    "    ).dropDuplicates([\"location_id_nk_pk\"])\n",
    "   \n",
    "    # Union locations\n",
    "    all_locations = chicago_locations.unionByName(dallas_locations)\n",
    "   \n",
    "    # Format columns without surrogate keys\n",
    "    dim_location = all_locations.select(\n",
    "        col(\"location_id_nk_pk\").cast(\"varchar(200)\"),  # Natural key as primary key\n",
    "        col(\"street_address\").cast(\"varchar(150)\"),\n",
    "        col(\"city\").cast(\"varchar(50)\"),\n",
    "        col(\"state\").cast(\"varchar(50)\"),\n",
    "        col(\"zip\").cast(\"varchar(50)\"),\n",
    "        col(\"latitude\").cast(\"float\"),\n",
    "        col(\"longitude\").cast(\"float\"),\n",
    "        col(\"location_id_nk_pk\").cast(\"varchar(200)\").alias(\"location\"),\n",
    "        col(\"location_id_nk_pk\").cast(\"varchar(200)\").alias(\"data_source_id\"),\n",
    "        col(\"source_city\").cast(\"varchar(50)\").alias(\"data_workflow_name\"),\n",
    "        col(\"location_id_nk_pk\").cast(\"varchar(200)\").alias(\"dw_job_id\"),\n",
    "        current_timestamp().alias(\"dw_load_dt\")\n",
    "    )\n",
    "   \n",
    "    return dim_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0852e30d-a15c-4d96-ab99-c09de61e124f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Restaurant dimension with SCD Type 2 - using natural key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43150de4-10b1-42f7-8a79-d1beaaaca7fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.view(\n",
    "    name=\"restaurant_updates\"\n",
    ")\n",
    "def restaurant_updates():\n",
    "    \"\"\"Prepare restaurant updates for SCD2 processing from streaming silver tables\"\"\"\n",
    "   \n",
    "    # Chicago restaurants\n",
    "    chicago_restaurants = dlt.read_stream(\"silver.chicago_inspections_silver\").select(\n",
    "        concat(lit(\"CHI_\"), col(\"license\"), lit(\"_\"), col(\"latitude\"), lit(\"_\"), col(\"longitude\")).alias(\"restaurant_id_nk\"),  # Natural key\n",
    "        col(\"dba_name\").alias(\"restaurant_name\"),\n",
    "        col(\"aka_name\").alias(\"aka_known_as_name\"),\n",
    "        col(\"license\").cast(\"double\").cast(\"bigint\").alias(\"license_number\"),\n",
    "        col(\"facility_type\"),\n",
    "        col(\"risk\").alias(\"risk_level\"),\n",
    "        lit(\"CHI\").alias(\"source_city\"),\n",
    "        col(\"_ingestion_timestamp\").alias(\"source_timestamp\")\n",
    "    ).filter(\n",
    "        col(\"dba_name\").isNotNull() &\n",
    "        col(\"license\").isNotNull() &\n",
    "        col(\"latitude\").isNotNull() &\n",
    "        col(\"longitude\").isNotNull()\n",
    "    )\n",
    "   \n",
    "    # Dallas restaurants\n",
    "    dallas_restaurants = dlt.read_stream(\"silver.dallas_inspections_silver\").select(\n",
    "        concat(lit(\"DAL_\"), col(\"restaurant_name\"), lit(\"_\"), col(\"lat\"), lit(\"_\"), col(\"long\")).alias(\"restaurant_id_nk\"),  # Natural key\n",
    "        col(\"restaurant_name\"),\n",
    "        lit(None).cast(\"varchar(100)\").alias(\"aka_known_as_name\"),\n",
    "        lit(None).cast(\"bigint\").alias(\"license_number\"),\n",
    "        lit(\"Restaurant\").alias(\"facility_type\"),\n",
    "        when(col(\"inspection_score\") < 80, \"Risk 1 (High)\")\n",
    "        .when(col(\"inspection_score\") < 90, \"Risk 2 (Medium)\")\n",
    "        .otherwise(\"Risk 3 (Low)\").alias(\"risk_level\"),\n",
    "        lit(\"DAL\").alias(\"source_city\"),\n",
    "        col(\"_ingestion_timestamp\").alias(\"source_timestamp\")\n",
    "    ).filter(\n",
    "        col(\"restaurant_name\").isNotNull() &\n",
    "        col(\"lat\").isNotNull() &\n",
    "        col(\"long\").isNotNull()\n",
    "    )\n",
    "   \n",
    "    # Union and deduplicate\n",
    "    combined_restaurants = chicago_restaurants.unionByName(dallas_restaurants) \\\n",
    "        .withWatermark(\"source_timestamp\", \"1 hour\") \\\n",
    "        .dropDuplicates([\"restaurant_id_nk\", \"source_timestamp\"])\n",
    "   \n",
    "    # Drop any reserved SCD2 columns if they exist to ensure clean processing\n",
    "    scd2_reserved_columns = [\"_change_type\", \"_commit_version\", \"_commit_timestamp\"]\n",
    "    for col_name in scd2_reserved_columns:\n",
    "        if col_name in combined_restaurants.columns:\n",
    "            combined_restaurants = combined_restaurants.drop(col_name)\n",
    "   \n",
    "    return combined_restaurants\n",
    " \n",
    "# Apply SCD Type 2 using DLT's built-in functionality\n",
    "dlt.create_streaming_table(\n",
    "    name=\"gold.dim_restaurant_scd2\",\n",
    "    comment=\"Restaurant dimension with SCD Type 2 - tracks historical changes with natural keys\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\"\n",
    "        # CDF removed - SCD2 already tracks changes internally\n",
    "    }\n",
    ")\n",
    " \n",
    "dlt.apply_changes(\n",
    "    target=\"gold.dim_restaurant_scd2\",\n",
    "    source=\"restaurant_updates\",\n",
    "    keys=[\"restaurant_id_nk\"],  # Natural key\n",
    "    sequence_by=\"source_timestamp\",\n",
    "    apply_as_deletes=None,\n",
    "    except_column_list=[\"source_timestamp\"],\n",
    "    stored_as_scd_type=2,\n",
    "    track_history_column_list=[\n",
    "        \"restaurant_name\",\n",
    "        \"aka_known_as_name\",\n",
    "        \"risk_level\",\n",
    "        \"facility_type\",\n",
    "        \"license_number\"\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22ed5f26-65e2-4964-92a8-ee39a7069709",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " dim violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae138d57-480b-43c2-a606-2a9a20e935f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " \n",
    "@dlt.table(\n",
    "    name=\"gold.dim_violation\",\n",
    "    comment=\"Violation codes and descriptions dimension - Streaming with Natural Keys\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"delta.enableChangeDataFeed\": \"true\"\n",
    "    }\n",
    ")\n",
    "def dim_violation():\n",
    "    \"\"\"Create violation dimension as a streaming table using composite natural key\"\"\"\n",
    "    \n",
    "    # Parse Chicago violations\n",
    "    chicago_violations = dlt.read_stream(\"silver.chicago_inspections_silver\") \\\n",
    "        .select(explode(split(col(\"violations\"), r\"\\|\")).alias(\"violation_text\")) \\\n",
    "        .filter(col(\"violation_text\") != \"\") \\\n",
    "        .select(\n",
    "            regexp_extract(col(\"violation_text\"), r\"^(\\d+)\\.\", 1).alias(\"violation_code\"),\n",
    "            trim(regexp_extract(col(\"violation_text\"), r\"^\\d+\\.\\s*(.+?)\\s*-\\s*Comments:\", 1)).alias(\"violation_title\"),\n",
    "            lit(\"CHI\").alias(\"source_city\")\n",
    "        ).filter(col(\"violation_code\") != \"\") \\\n",
    "        .dropDuplicates([\"violation_code\", \"source_city\"])\n",
    "    \n",
    "    # Parse Dallas violations\n",
    "    dallas_violations_list = []\n",
    "    for i in range(1, 26):\n",
    "        dallas_viol = dlt.read_stream(\"silver.dallas_inspections_silver\") \\\n",
    "            .select(\n",
    "                regexp_extract(col(f\"violation_description_{i}\"), r\"^\\*?(\\d+)\", 1).alias(\"violation_code\"),\n",
    "                trim(regexp_replace(col(f\"violation_description_{i}\"), r\"^\\*?\\d+\\s*\", \"\")).alias(\"violation_title\"),\n",
    "                lit(\"DAL\").alias(\"source_city\")\n",
    "            ).filter(col(f\"violation_description_{i}\").isNotNull())\n",
    "        dallas_violations_list.append(dallas_viol)\n",
    "    \n",
    "    # Union all Dallas violations\n",
    "    dallas_violations = reduce(lambda df1, df2: df1.unionByName(df2), dallas_violations_list) \\\n",
    "        .dropDuplicates([\"violation_code\", \"source_city\"])\n",
    "    \n",
    "    # Union all violations\n",
    "    all_violations = chicago_violations.unionByName(dallas_violations)\n",
    "    \n",
    "    # Create dimension with composite natural key\n",
    "    dim_violation = all_violations.select(\n",
    "        concat(col(\"source_city\"), lit(\"_\"), col(\"violation_code\")).cast(\"varchar(100)\").alias(\"violation_id_nk_pk\"),  # Natural key\n",
    "        col(\"violation_code\").cast(\"varchar(50)\"),\n",
    "        col(\"violation_title\").cast(\"varchar(1000)\").alias(\"violation_description\"),\n",
    "        concat(col(\"source_city\"), lit(\"_\"), col(\"violation_code\")).cast(\"varchar(100)\").alias(\"data_source_id\"),\n",
    "        col(\"source_city\").cast(\"varchar(50)\").alias(\"data_workflow_name\"),\n",
    "        col(\"violation_code\").cast(\"varchar(50)\").alias(\"dw_job_id\"),\n",
    "        current_timestamp().alias(\"dw_load_dt\")\n",
    "    )\n",
    "    \n",
    "    return dim_violation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71fbfa2d-c355-4123-90f6-e0a77b642e22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "dim_inspection_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "570f3a34-7376-488c-ba4b-bec52eafd669",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@dlt.table(\n",
    "    name=\"gold.dim_inspection_type\",\n",
    "    comment=\"Inspection type dimension - Streaming with Natural Keys\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"delta.enableChangeDataFeed\": \"true\"\n",
    "    }\n",
    ")\n",
    "def dim_inspection_type():\n",
    "    \"\"\"Create inspection type dimension\"\"\"\n",
    "    \n",
    "    # Get unique inspection types from both cities\n",
    "    chicago_types = dlt.read_stream(\"silver.chicago_inspections_silver\") \\\n",
    "        .select(col(\"inspection_type\"), lit(\"CHI\").alias(\"source_city\")) \\\n",
    "        .filter(col(\"inspection_type\").isNotNull()) \\\n",
    "        .dropDuplicates([\"inspection_type\"])\n",
    "    \n",
    "    dallas_types = dlt.read_stream(\"silver.dallas_inspections_silver\") \\\n",
    "        .select(col(\"inspection_type\"), lit(\"DAL\").alias(\"source_city\")) \\\n",
    "        .filter(col(\"inspection_type\").isNotNull()) \\\n",
    "        .dropDuplicates([\"inspection_type\"])\n",
    "    \n",
    "    # Union and create dimension\n",
    "    all_types = chicago_types.union(dallas_types) \\\n",
    "        .dropDuplicates([\"inspection_type\"])\n",
    "    \n",
    "    return all_types.select(\n",
    "        col(\"inspection_type\").cast(\"varchar(100)\").alias(\"inspection_type_nk_pk\"),\n",
    "        col(\"inspection_type\").cast(\"varchar(100)\").alias(\"inspection_type_name\"),\n",
    "        when(col(\"inspection_type\").contains(\"Complaint\"), \"Complaint-Based\")\n",
    "        .when(col(\"inspection_type\").contains(\"Re-Inspection\"), \"Follow-up\")\n",
    "        .when(col(\"inspection_type\").contains(\"License\"), \"Licensing\")\n",
    "        .otherwise(\"Routine\").alias(\"inspection_category\"),\n",
    "        current_timestamp().alias(\"dw_load_dt\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95c9b284-615d-4921-8c26-00d655306d5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "fact_inspection and bridge tables to manage relationships(many to many)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b17d65d6-3463-4dfb-b2e8-292d3b932df2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# =====================================================\n",
    "# FACT TABLE - STREAMING WITH NATURAL KEYS\n",
    "# =====================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold.fact_inspection\",\n",
    "    comment=\"Unified fact table for all inspections - Streaming with Natural Keys\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"delta.enableChangeDataFeed\": \"true\"\n",
    "    }\n",
    ")\n",
    "def fact_inspection():\n",
    "    \"\"\"Create the unified fact table as streaming using natural keys\"\"\"\n",
    "    \n",
    "    # Process Chicago inspections\n",
    "    chicago_base = dlt.read_stream(\"silver.chicago_inspections_silver\")\n",
    "    \n",
    "    # Create fact records with natural keys\n",
    "    chicago_fact = chicago_base.select(\n",
    "        col(\"inspection_id\").cast(\"varchar(100)\").alias(\"fact_inspection_nk_pk\"),  # Natural key\n",
    "        concat(lit(\"CHI_\"), col(\"license\"), lit(\"_\"), col(\"latitude\"), lit(\"_\"), col(\"longitude\")).alias(\"restaurant_id_nk\"),\n",
    "        concat_ws(\"_\", lit(\"CHI\"), col(\"address\"), col(\"zip\")).alias(\"location_id_nk\"),\n",
    "        date_format(to_date(col(\"inspection_date\")), \"yyyyMMdd\").cast(\"integer\").alias(\"date_id_nk\"),\n",
    "        col(\"inspection_type\").cast(\"varchar(100)\").alias(\"inspection_type_nk\"),  # NEW: Link to inspection type dimension\n",
    "        col(\"results\").cast(\"varchar(50)\").alias(\"result\"),\n",
    "        col(\"violation_score\").cast(\"integer\").alias(\"violation_score\"),\n",
    "        col(\"violation_count\").cast(\"integer\").alias(\"violation_count\"),  # Fixed column name\n",
    "        col(\"inspection_type\").cast(\"varchar(50)\").alias(\"inspection_type\"),\n",
    "        col(\"inspection_id\").cast(\"varchar(100)\").alias(\"data_source_id\"),\n",
    "        lit(\"CHI\").cast(\"varchar(50)\").alias(\"data_workflow_name\"),\n",
    "        col(\"inspection_id\").cast(\"varchar(50)\").alias(\"dw_job_id\"),\n",
    "        current_timestamp().alias(\"dw_load_dt\"),\n",
    "        col(\"_ingestion_timestamp\").alias(\"streaming_timestamp\")\n",
    "    )\n",
    "    \n",
    "    # Process Dallas inspections\n",
    "    dallas_base = dlt.read_stream(\"silver.dallas_inspections_silver\")\n",
    "    \n",
    "    # Create inspection ID for Dallas\n",
    "    dallas_with_id = dallas_base.withColumn(\n",
    "        \"inspection_id\",\n",
    "        concat(col(\"restaurant_name\"), lit(\"_\"), col(\"inspection_date\"))\n",
    "    )\n",
    "    \n",
    "    # Create fact records with natural keys\n",
    "    dallas_fact = dallas_with_id.select(\n",
    "        col(\"inspection_id\").cast(\"varchar(100)\").alias(\"fact_inspection_nk_pk\"),  # Natural key\n",
    "        concat(lit(\"DAL_\"), col(\"restaurant_name\"), lit(\"_\"), col(\"lat\"), lit(\"_\"), col(\"long\")).alias(\"restaurant_id_nk\"),\n",
    "        concat_ws(\"_\", lit(\"DAL\"), col(\"street_address\"), col(\"zip_code\")).alias(\"location_id_nk\"),\n",
    "        date_format(to_date(col(\"inspection_date\")), \"yyyyMMdd\").cast(\"integer\").alias(\"date_id_nk\"),\n",
    "        col(\"inspection_type\").cast(\"varchar(100)\").alias(\"inspection_type_nk\"),  # NEW: Link to inspection type dimension\n",
    "        when(col(\"inspection_score\") >= 70, \"Pass\").otherwise(\"Fail\").cast(\"varchar(50)\").alias(\"result\"),\n",
    "        col(\"inspection_score\").cast(\"integer\").alias(\"violation_score\"),\n",
    "        col(\"violation_count\").cast(\"integer\").alias(\"violation_count\"),\n",
    "        col(\"inspection_type\").cast(\"varchar(50)\").alias(\"inspection_type\"),\n",
    "        col(\"inspection_id\").cast(\"varchar(100)\").alias(\"data_source_id\"),\n",
    "        lit(\"DAL\").cast(\"varchar(50)\").alias(\"data_workflow_name\"),\n",
    "        col(\"inspection_id\").cast(\"varchar(50)\").alias(\"dw_job_id\"),\n",
    "        current_timestamp().alias(\"dw_load_dt\"),\n",
    "        col(\"_ingestion_timestamp\").alias(\"streaming_timestamp\")\n",
    "    )\n",
    "    \n",
    "    # Union both cities\n",
    "    fact_inspection_union = chicago_fact.unionByName(dallas_fact) \\\n",
    "        .withWatermark(\"streaming_timestamp\", \"2 hours\") \\\n",
    "        .dropDuplicates([\"fact_inspection_nk_pk\"])\n",
    "    \n",
    "    return fact_inspection_union\n",
    "\n",
    "# =====================================================\n",
    "# BRIDGE TABLES FOR COMPLETE STAR SCHEMA\n",
    "# =====================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold.bridge_inspection_violation\",\n",
    "    comment=\"Bridge table linking inspections to violations - Streaming with Natural Keys\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"delta.enableChangeDataFeed\": \"true\"\n",
    "    }\n",
    ")\n",
    "def bridge_inspection_violation():\n",
    "    \"\"\"Create bridge table for many-to-many relationship between inspections and violations\"\"\"\n",
    "    \n",
    "    # Chicago inspection-violation relationships\n",
    "    chicago_bridge = dlt.read_stream(\"silver.chicago_inspections_silver\") \\\n",
    "        .select(\n",
    "            col(\"inspection_id\"),\n",
    "            explode(split(col(\"violations\"), r\"\\|\")).alias(\"violation_text\"),\n",
    "            col(\"_ingestion_timestamp\").alias(\"streaming_timestamp\")\n",
    "        ).filter(col(\"violation_text\") != \"\") \\\n",
    "        .select(\n",
    "            col(\"inspection_id\").cast(\"varchar(100)\").alias(\"inspection_id_nk\"),\n",
    "            concat(lit(\"CHI_\"), regexp_extract(col(\"violation_text\"), r\"^(\\d+)\\.\", 1)).cast(\"varchar(100)\").alias(\"violation_id_nk\"),\n",
    "            lit(\"CHI\").alias(\"source_city\"),\n",
    "            col(\"streaming_timestamp\")\n",
    "        ).filter(col(\"violation_id_nk\") != \"CHI_\")\n",
    "    \n",
    "    # Dallas inspection-violation relationships\n",
    "    dallas_base = dlt.read_stream(\"silver.dallas_inspections_silver\")\n",
    "    \n",
    "    dallas_bridge_list = []\n",
    "    for i in range(1, 26):\n",
    "        dallas_viol = dallas_base.filter(col(f\"violation_description_{i}\").isNotNull()).select(\n",
    "            concat(col(\"restaurant_name\"), lit(\"_\"), col(\"inspection_date\")).cast(\"varchar(100)\").alias(\"inspection_id_nk\"),\n",
    "            concat(lit(\"DAL_\"), regexp_extract(col(f\"violation_description_{i}\"), r\"^\\*?(\\d+)\", 1)).cast(\"varchar(100)\").alias(\"violation_id_nk\"),\n",
    "            lit(\"DAL\").alias(\"source_city\"),\n",
    "            col(\"_ingestion_timestamp\").alias(\"streaming_timestamp\")\n",
    "        )\n",
    "        dallas_bridge_list.append(dallas_viol)\n",
    "    \n",
    "    dallas_bridge = reduce(lambda df1, df2: df1.unionByName(df2), dallas_bridge_list)\n",
    "    \n",
    "    # Union both cities\n",
    "    bridge_table = chicago_bridge.unionByName(dallas_bridge) \\\n",
    "        .withWatermark(\"streaming_timestamp\", \"2 hours\") \\\n",
    "        .dropDuplicates([\"inspection_id_nk\", \"violation_id_nk\"]) \\\n",
    "        .select(\n",
    "            concat(col(\"inspection_id_nk\"), lit(\"_\"), col(\"violation_id_nk\")).cast(\"varchar(200)\").alias(\"bridge_id_nk_pk\"),\n",
    "            col(\"inspection_id_nk\"),\n",
    "            col(\"violation_id_nk\"),\n",
    "            col(\"source_city\").cast(\"varchar(50)\").alias(\"data_workflow_name\"),\n",
    "            current_timestamp().alias(\"dw_load_dt\")\n",
    "        )\n",
    "    \n",
    "    return bridge_table\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold.bridge_inspection_violation_detail\",\n",
    "    comment=\"Bridge table linking inspections to violation details with comments - Streaming\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"delta.enableChangeDataFeed\": \"true\"\n",
    "    }\n",
    ")\n",
    "def bridge_inspection_violation_detail():\n",
    "    \"\"\"Create bridge table that includes violation comments and details\"\"\"\n",
    "    \n",
    "    # Chicago inspection-violation details\n",
    "    chicago_details = dlt.read_stream(\"silver.chicago_inspections_silver\") \\\n",
    "        .select(\n",
    "            col(\"inspection_id\"),\n",
    "            explode(split(col(\"violations\"), r\"\\|\")).alias(\"violation_text\"),\n",
    "            col(\"_ingestion_timestamp\").alias(\"streaming_timestamp\")\n",
    "        ).filter(col(\"violation_text\") != \"\") \\\n",
    "        .select(\n",
    "            col(\"inspection_id\").cast(\"varchar(100)\").alias(\"inspection_id_nk\"),\n",
    "            concat(lit(\"CHI_\"), regexp_extract(col(\"violation_text\"), r\"^(\\d+)\\.\", 1)).cast(\"varchar(100)\").alias(\"violation_id_nk\"),\n",
    "            regexp_extract(col(\"violation_text\"), r\"^(\\d+)\\.\", 1).alias(\"violation_code\"),\n",
    "            trim(regexp_extract(col(\"violation_text\"), r\"-\\s*Comments:\\s*(.+)$\", 1)).alias(\"violation_comment\"),\n",
    "            lit(\"CHI\").alias(\"source_city\"),\n",
    "            col(\"streaming_timestamp\")\n",
    "        ).filter(col(\"violation_id_nk\") != \"CHI_\")\n",
    "    \n",
    "    # Dallas inspection-violation details\n",
    "    dallas_base = dlt.read_stream(\"silver.dallas_inspections_silver\")\n",
    "    \n",
    "    dallas_details_list = []\n",
    "    for i in range(1, 26):\n",
    "        dallas_detail = dallas_base.filter(col(f\"violation_description_{i}\").isNotNull()).select(\n",
    "            concat(col(\"restaurant_name\"), lit(\"_\"), col(\"inspection_date\")).cast(\"varchar(100)\").alias(\"inspection_id_nk\"),\n",
    "            concat(lit(\"DAL_\"), regexp_extract(col(f\"violation_description_{i}\"), r\"^\\*?(\\d+)\", 1)).cast(\"varchar(100)\").alias(\"violation_id_nk\"),\n",
    "            regexp_extract(col(f\"violation_description_{i}\"), r\"^\\*?(\\d+)\", 1).alias(\"violation_code\"),\n",
    "            col(f\"violation_memo_{i}\").alias(\"violation_comment\"),\n",
    "            lit(\"DAL\").alias(\"source_city\"),\n",
    "            col(\"_ingestion_timestamp\").alias(\"streaming_timestamp\")\n",
    "        )\n",
    "        dallas_details_list.append(dallas_detail)\n",
    "    \n",
    "    dallas_details = reduce(lambda df1, df2: df1.unionByName(df2), dallas_details_list)\n",
    "    \n",
    "    # Union both cities\n",
    "    bridge_detail_table = chicago_details.unionByName(dallas_details) \\\n",
    "        .withWatermark(\"streaming_timestamp\", \"2 hours\") \\\n",
    "        .dropDuplicates([\"inspection_id_nk\", \"violation_id_nk\"]) \\\n",
    "        .select(\n",
    "            concat(col(\"inspection_id_nk\"), lit(\"_\"), col(\"violation_id_nk\")).cast(\"varchar(200)\").alias(\"bridge_detail_id_nk_pk\"),\n",
    "            col(\"inspection_id_nk\"),\n",
    "            col(\"violation_id_nk\"),\n",
    "            col(\"violation_code\").cast(\"varchar(50)\"),\n",
    "            col(\"violation_comment\").cast(\"varchar(1000)\"),\n",
    "            col(\"source_city\").cast(\"varchar(50)\").alias(\"data_workflow_name\"),\n",
    "            current_timestamp().alias(\"dw_load_dt\")\n",
    "        )\n",
    "    \n",
    "    return bridge_detail_table"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DIm_and_Fact_Tables_With_SCD_Type_2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
